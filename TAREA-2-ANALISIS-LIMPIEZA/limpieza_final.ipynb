{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "44c21d86-2e61-408c-9f3f-3b47d28fadb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import hashlib\n",
    "from langdetect import detect, DetectorFactory\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "\n",
    "# Configuraci√≥n para detecci√≥n de idioma consistente\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# Configuraci√≥n de pandas para mostrar m√°s columnas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "665b85f9-3f2c-4ac6-bc0a-a68217dd8393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInformaci√≥n inicial del dataset:\u001b[0m\n",
      "Registros totales: 4052\n",
      "Columnas originales: ['Tweet_ID', 'Username', 'Text', 'Created_At', 'Location_Mentioned', 'tweet_length']\n",
      "\n",
      "Primeras filas del dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Username</th>\n",
       "      <th>Text</th>\n",
       "      <th>Created_At</th>\n",
       "      <th>Location_Mentioned</th>\n",
       "      <th>tweet_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1828598353636086250</td>\n",
       "      <td>SAJO</td>\n",
       "      <td>Se fue la luz y se da√±√≥ el panel electr√≥nico del elevador y el AC. Luma nos est√° destruyendo y cobrando por hacerlo. Somos muchos los afectados. El desquite va. üëäüèªüëäüèªüëäüèª</td>\n",
       "      <td>2024-07-22</td>\n",
       "      <td>Quito</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1788212151393423687</td>\n",
       "      <td>üå∏‚ô°üå∏ElizŒ±Œ≤ŒµœÑhüå∏‚ô°üå∏</td>\n",
       "      <td>No quiero arrecharme, pero estos HDP de Corpoelec quitan la luz hoy q hay agua y se puede lavar!!! üò§\\n\\nCdo hay electricidad, no hay agua \\nCdo hay agua, no hay electricidad.\\nP√≥nganse d acuerdo n...</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>Azuay</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1801749927090847994</td>\n",
       "      <td>Jay Fonseca</td>\n",
       "      <td>üåå A dos d√≠as del apag√≥n masivo que dej√≥ a medio archipi√©lago a oscuras, ciudadanos reclamaron esta tarde la salida de LUMA Energy y de Genera PR, los dos operadores privados del sistema el√©ctrico....</td>\n",
       "      <td>2024-10-15</td>\n",
       "      <td>Guayaquil</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tweet_ID         Username  \\\n",
       "0  1828598353636086250             SAJO   \n",
       "1  1788212151393423687  üå∏‚ô°üå∏ElizŒ±Œ≤ŒµœÑhüå∏‚ô°üå∏   \n",
       "2  1801749927090847994      Jay Fonseca   \n",
       "\n",
       "                                                                                                                                                                                                      Text  \\\n",
       "0                                  Se fue la luz y se da√±√≥ el panel electr√≥nico del elevador y el AC. Luma nos est√° destruyendo y cobrando por hacerlo. Somos muchos los afectados. El desquite va. üëäüèªüëäüèªüëäüèª   \n",
       "1  No quiero arrecharme, pero estos HDP de Corpoelec quitan la luz hoy q hay agua y se puede lavar!!! üò§\\n\\nCdo hay electricidad, no hay agua \\nCdo hay agua, no hay electricidad.\\nP√≥nganse d acuerdo n...   \n",
       "2  üåå A dos d√≠as del apag√≥n masivo que dej√≥ a medio archipi√©lago a oscuras, ciudadanos reclamaron esta tarde la salida de LUMA Energy y de Genera PR, los dos operadores privados del sistema el√©ctrico....   \n",
       "\n",
       "   Created_At Location_Mentioned  tweet_length  \n",
       "0  2024-07-22              Quito           167  \n",
       "1  2024-12-01              Azuay           257  \n",
       "2  2024-10-15          Guayaquil           299  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargar el dataset\n",
    "df = pd.read_csv('limpiar_enalces.csv')\n",
    "\n",
    "# Mostrar informaci√≥n inicial del dataset\n",
    "print(\"\\033[1mInformaci√≥n inicial del dataset:\\033[0m\")\n",
    "print(f\"Registros totales: {len(df)}\")\n",
    "print(f\"Columnas originales: {df.columns.tolist()}\")\n",
    "print(\"\\nPrimeras filas del dataset:\")\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d862b7ff-1007-4910-a4c4-85d999f14083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mHasheando Tweet_ID...\u001b[0m\n",
      "\u001b[1mEliminando columna Username...\u001b[0m\n",
      "\n",
      "\u001b[1mDataset despu√©s de hashear y eliminar:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Created_At</th>\n",
       "      <th>Location_Mentioned</th>\n",
       "      <th>tweet_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c3c923bab9a5006041fee2df8da9a2173b2de335f62342eebe05f0208c97e6c1</td>\n",
       "      <td>Se fue la luz y se da√±√≥ el panel electr√≥nico del elevador y el AC. Luma nos est√° destruyendo y cobrando por hacerlo. Somos muchos los afectados. El desquite va. üëäüèªüëäüèªüëäüèª</td>\n",
       "      <td>2024-07-22</td>\n",
       "      <td>Quito</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23cf0973031f6388a6bacb5306160f57e5f23cbdbb597cdb6726ca6e459aa3e5</td>\n",
       "      <td>No quiero arrecharme, pero estos HDP de Corpoelec quitan la luz hoy q hay agua y se puede lavar!!! üò§\\n\\nCdo hay electricidad, no hay agua \\nCdo hay agua, no hay electricidad.\\nP√≥nganse d acuerdo n...</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>Azuay</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33da3cb8621b2ce82a4eb6441dfabf4a059ddde7348fadebdb78a4b11370728a</td>\n",
       "      <td>üåå A dos d√≠as del apag√≥n masivo que dej√≥ a medio archipi√©lago a oscuras, ciudadanos reclamaron esta tarde la salida de LUMA Energy y de Genera PR, los dos operadores privados del sistema el√©ctrico....</td>\n",
       "      <td>2024-10-15</td>\n",
       "      <td>Guayaquil</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           Tweet_ID  \\\n",
       "0  c3c923bab9a5006041fee2df8da9a2173b2de335f62342eebe05f0208c97e6c1   \n",
       "1  23cf0973031f6388a6bacb5306160f57e5f23cbdbb597cdb6726ca6e459aa3e5   \n",
       "2  33da3cb8621b2ce82a4eb6441dfabf4a059ddde7348fadebdb78a4b11370728a   \n",
       "\n",
       "                                                                                                                                                                                                      Text  \\\n",
       "0                                  Se fue la luz y se da√±√≥ el panel electr√≥nico del elevador y el AC. Luma nos est√° destruyendo y cobrando por hacerlo. Somos muchos los afectados. El desquite va. üëäüèªüëäüèªüëäüèª   \n",
       "1  No quiero arrecharme, pero estos HDP de Corpoelec quitan la luz hoy q hay agua y se puede lavar!!! üò§\\n\\nCdo hay electricidad, no hay agua \\nCdo hay agua, no hay electricidad.\\nP√≥nganse d acuerdo n...   \n",
       "2  üåå A dos d√≠as del apag√≥n masivo que dej√≥ a medio archipi√©lago a oscuras, ciudadanos reclamaron esta tarde la salida de LUMA Energy y de Genera PR, los dos operadores privados del sistema el√©ctrico....   \n",
       "\n",
       "   Created_At Location_Mentioned  tweet_length  \n",
       "0  2024-07-22              Quito           167  \n",
       "1  2024-12-01              Azuay           257  \n",
       "2  2024-10-15          Guayaquil           299  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Funci√≥n para hashear el Tweet_ID\n",
    "def hashear_id(tweet_id):\n",
    "    if pd.isna(tweet_id):\n",
    "        return None\n",
    "    return hashlib.sha256(str(tweet_id).encode()).hexdigest()\n",
    "\n",
    "# Aplicar hashing al Tweet_ID\n",
    "print(\"\\033[1mHasheando Tweet_ID...\\033[0m\")\n",
    "df['Tweet_ID'] = df['Tweet_ID'].apply(hashear_id)\n",
    "\n",
    "# Eliminar la columna Username\n",
    "print(\"\\033[1mEliminando columna Username...\\033[0m\")\n",
    "df.drop(columns=['Username'], inplace=True)\n",
    "\n",
    "# Verificar cambios\n",
    "print(\"\\n\\033[1mDataset despu√©s de hashear y eliminar:\\033[0m\")\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e01b8bc3-cb3b-4ab2-a530-c58a4417ff36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mProcesando limpieza de texto...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4052/4052 [00:00<00:00, 19478.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRegistros despu√©s de limpieza:\u001b[0m 4052\n",
      "\u001b[1mRegistros eliminados:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "def limpiar_texto_mejorado(texto):\n",
    "    if pd.isna(texto) or texto == '':\n",
    "        return \"\"\n",
    "    \n",
    "    # Convertir a string por si acaso\n",
    "    texto = str(texto)\n",
    "    \n",
    "    # 1. Eliminar saltos de l√≠nea y unir todo en una l√≠nea\n",
    "    texto = re.sub(r'\\n|\\r|\\t', ' ', texto)\n",
    "    \n",
    "    # 2. Eliminar enlaces (http, https, t.co, etc.)\n",
    "    texto = re.sub(r'http\\S+|www\\S+|https?://\\S+|t\\.co/\\S+', '', texto, flags=re.IGNORECASE)\n",
    "    \n",
    "    # 3. Eliminar menciones (@usuario)\n",
    "    texto = re.sub(r'@\\w+', '', texto)\n",
    "    \n",
    "    # 4. Eliminar completamente el hashtag y todo lo que le sigue\n",
    "    texto = re.sub(r'#\\S+', '', texto)  # \n",
    "    \n",
    "    # 5. Eliminar emojis y s√≠mbolos especiales (patr√≥n ampliado)\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticonos\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # s√≠mbolos & pictogramas\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transporte & s√≠mbolos\n",
    "        u\"\\U0001F700-\\U0001F77F\"  # alquimia\n",
    "        u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "        u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "        u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "        u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "        u\"\\U000024C2-\\U0001F251\" \n",
    "        u\"\\U0001F004-\\U0001F0CF\"\n",
    "        u\"\\U0001F170-\\U0001F251\"\n",
    "        \"‚Ä¢‚Üí‚Üê‚Üë‚Üì¬´¬ª‚è∞\"  # S√≠mbolos adicionales espec√≠ficos\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    texto = emoji_pattern.sub(r'', texto)\n",
    "    \n",
    "    # 6. Eliminar caracteres especiales pero conservar signos de puntuaci√≥n b√°sicos\n",
    "    caracteres_especiales = r'[|*{}\\[\\]()/&%\"¬¨=¬∞$\\'¬ø¬°~+]'\n",
    "    texto = re.sub(caracteres_especiales, ' ', texto)\n",
    "    \n",
    "    # 7. Eliminar n√∫meros\n",
    "    texto = re.sub(r'\\d+', '', texto)\n",
    "    \n",
    "    # 8. Convertir a min√∫sculas\n",
    "    texto = texto.lower()\n",
    "    \n",
    "    # 9. Eliminar puntos suspensivos, comillas y patrones especiales\n",
    "    texto = re.sub(r'\\.{2,}', ' ', texto)  # Puntos suspensivos\n",
    "    texto = re.sub(r'‚Ä¶', ' ', texto)  # Puntos suspensivos unicode\n",
    "    texto = re.sub(r'¬¥|`', '', texto)  # Acentos sueltos\n",
    "    \n",
    "    # 10. Eliminar comillas de todo tipo (incluyendo las angulares)\n",
    "    comillas = r'[\\'\\\"\\‚Äò\\‚Äô\\‚Äú\\‚Äù\\¬¥\\`¬´¬ª]'\n",
    "    texto = re.sub(comillas, '', texto)\n",
    "    \n",
    "    # 11. Normalizar espacios m√∫ltiples y bordes\n",
    "    texto = re.sub(r'\\s{2,}', ' ', texto)  # Espacios m√∫ltiples\n",
    "    texto = texto.strip()\n",
    "    \n",
    "    # 13. Eliminar palabras sueltas muy cortas (1-2 letras) que no aportan significado\n",
    "    palabras_relevantes = ['no', 'si', 'se', 'me', 'te', 'le', 'lo', 'la', 'los', 'las', \n",
    "                          'un', 'una', 'uno', 'unos', 'unas', 'al', 'del', '√©l', 'ella']\n",
    "    texto = ' '.join([word for word in texto.split() \n",
    "                     if len(word) > 2 or word in palabras_relevantes])\n",
    "    \n",
    "    return texto\n",
    "\n",
    "# Funci√≥n para detectar texto v√°lido (no vac√≠o despu√©s de limpieza)\n",
    "def es_texto_valido(texto):\n",
    "    texto_limpio = limpiar_texto_mejorado(texto)\n",
    "    return len(texto_limpio.strip()) > 3  # Consideramos v√°lido si tiene m√°s de 3 caracteres\n",
    "\n",
    "# Aplicar limpieza mejorada con barra de progreso\n",
    "print(\"\\033[1mProcesando limpieza de texto...\\033[0m\")\n",
    "tqdm.pandas()\n",
    "df['Text_Clean'] = df['Text'].progress_apply(limpiar_texto_mejorado)\n",
    "\n",
    "# Filtrar solo textos v√°lidos\n",
    "df_filtrado = df[df['Text'].apply(es_texto_valido)].copy()\n",
    "print(f\"\\033[1mRegistros despu√©s de limpieza:\\033[0m {len(df_filtrado)}\")\n",
    "print(f\"\\033[1mRegistros eliminados:\\033[0m {len(df) - len(df_filtrado)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a97a5d81-33d3-4f37-bb3f-ca7a18d2abf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFiltrando por idioma espa√±ol...\u001b[0m\n",
      "\u001b[1mRegistros finales:\u001b[0m 3815\n",
      "\u001b[1mRegistros eliminados por idioma:\u001b[0m 237\n"
     ]
    }
   ],
   "source": [
    "# Funci√≥n mejorada para detecci√≥n de idioma con manejo de errores\n",
    "def es_espanol_mejorado(texto):\n",
    "    try:\n",
    "        # Si el texto es muy corto, no podemos detectar idioma confiablemente\n",
    "        if len(texto) < 10:\n",
    "            return True  # Asumimos que es espa√±ol para no perder datos\n",
    "        \n",
    "        # Detectar idioma\n",
    "        return detect(texto) == 'es'\n",
    "    except:\n",
    "        return True  # En caso de error, lo mantenemos para no perder datos\n",
    "\n",
    "# Filtrar por idioma espa√±ol (con enfoque conservador para no perder datos)\n",
    "print(\"\\033[1mFiltrando por idioma espa√±ol...\\033[0m\")\n",
    "df_final = df_filtrado[df_filtrado['Text_Clean'].apply(es_espanol_mejorado)].copy()\n",
    "print(f\"\\033[1mRegistros finales:\\033[0m {len(df_final)}\")\n",
    "print(f\"\\033[1mRegistros eliminados por idioma:\\033[0m {len(df_filtrado) - len(df_final)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0afe38f1-da9c-4369-9643-1336b8e9b852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3815/3815 [00:00<00:00, 47132.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mVerificaci√≥n Final de Ruido Residual:\u001b[0m\n",
      "URLs residuales: 0 tweets (0.00%)\n",
      "HTML tags: 0 tweets (0.00%)\n",
      "Puntuaci√≥n m√∫ltiple: 0 tweets (0.00%)\n",
      "Caracteres especiales no permitidos: 7 tweets (0.19%)\n",
      "N√∫meros residuales: 0 tweets (0.00%)\n",
      "Letras repetidas: 0 tweets (0.00%)\n",
      "\n",
      "\u001b[1;32m¬°Proceso completado exitosamente!\u001b[0m\n",
      "Total tweets procesados: 3676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuraci√≥n para evitar warnings\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "# Funci√≥n de limpieza mejorada\n",
    "def limpiar_texto_final(texto):\n",
    "    if pd.isna(texto) or texto == '':\n",
    "        return \"\"\n",
    "    \n",
    "    texto = str(texto)\n",
    "    \n",
    "    # 1. Corregir letras repetidas (sin grupos problem√°ticos)\n",
    "    texto = re.sub(r'([a-zA-Z√°√©√≠√≥√∫√º√±√Å√â√ç√ì√ö√ú√ë])\\1{2,}', lambda m: m.group(1), texto)\n",
    "    \n",
    "    # 2. Eliminar caracteres especiales excepto tildes y √±\n",
    "    texto = re.sub(r'[^\\w\\s√°√©√≠√≥√∫√º√±√Å√â√ç√ì√ö√ú√ë]', '', texto)\n",
    "    \n",
    "    # 3. Normalizar espacios\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "    \n",
    "    return texto\n",
    "\n",
    "# Crear copia expl√≠cita para evitar SettingWithCopyWarning\n",
    "df_final_clean = df_final.copy()\n",
    "\n",
    "# Aplicar limpieza\n",
    "tqdm.pandas()\n",
    "df_final_clean.loc[:, 'Text_Final'] = df_final_clean['Text_Clean'].progress_apply(limpiar_texto_final)\n",
    "\n",
    "# Lista de palabras en portugu√©s a filtrar\n",
    "palabras_portugues = [\n",
    "    'obrigado', 'obrigada', 'por favor', 'voc√™', 'sim', 'n√£o', \n",
    "    'com licen√ßa', 'bom dia', 'boa tarde', 'boa noite', 'lou√ßa'\n",
    "]\n",
    "\n",
    "# Filtrar registros en portugu√©s (sin regex para evitar warnings)\n",
    "df_final_espanol = df_final_clean[\n",
    "    ~df_final_clean['Text_Final'].str.lower().str.contains('|'.join(palabras_portugues), na=False)\n",
    "]\n",
    "\n",
    "# Patrones de verificaci√≥n (sin grupos de captura)\n",
    "noise_patterns_final = {\n",
    "    'URLs residuales': r'https?:|www\\.',\n",
    "    'HTML tags': r'&lt;|&gt;|<[a-z]+>',\n",
    "    'Puntuaci√≥n m√∫ltiple': r'![!]+|\\?[\\?]+|\\.{2,}',\n",
    "    'Caracteres especiales no permitidos': r'[^a-z0-9\\s√°√©√≠√≥√∫√º√±]',\n",
    "    'N√∫meros residuales': r'\\b\\d\\d+\\b',\n",
    "    'Letras repetidas': r'([a-z√°√©√≠√≥√∫√º√±])\\1\\1'\n",
    "}\n",
    "\n",
    "print(\"\\n\\033[1mVerificaci√≥n Final de Ruido Residual:\\033[0m\")\n",
    "\n",
    "# Funci√≥n segura para contar patrones (sin warnings)\n",
    "def contar_patrones_seguro(serie, pattern):\n",
    "    try:\n",
    "        # Convertir a min√∫sculas y usar str.count() en lugar de contains()\n",
    "        return serie.str.lower().str.count(pattern).sum()\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "noise_counts = {}\n",
    "for name, pattern in noise_patterns_final.items():\n",
    "    count = contar_patrones_seguro(df_final_espanol['Text_Final'], pattern)\n",
    "    noise_counts[name] = count\n",
    "    print(f\"{name}: {count} tweets ({count/len(df_final_espanol)*100:.2f}%)\")\n",
    "\n",
    "# Mostrar solo resultados sin ejemplos espec√≠ficos\n",
    "print(\"\\n\\033[1;32m¬°Proceso completado exitosamente!\\033[0m\")\n",
    "print(f\"Total tweets procesados: {len(df_final_espanol)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "625f1826-35bb-4553-913d-358df4b423ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mColumnas en el dataset final:\u001b[0m\n",
      "['Tweet_ID', 'Created_At', 'Location_Mentioned', 'tweet_length', 'Text', 'Text_Final']\n",
      "\n",
      "\u001b[1mMuestra del dataset final:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Created_At</th>\n",
       "      <th>Location_Mentioned</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c3c923bab9a5006041fee2df8da9a2173b2de335f62342eebe05f0208c97e6c1</td>\n",
       "      <td>2024-07-22</td>\n",
       "      <td>Quito</td>\n",
       "      <td>167</td>\n",
       "      <td>Se fue la luz y se da√±√≥ el panel electr√≥nico del elevador y el AC. Luma nos est√° destruyendo y cobrando por hacerlo. Somos muchos los afectados. El desquite va. üëäüèªüëäüèªüëäüèª</td>\n",
       "      <td>se fue la luz se da√±√≥ panel electr√≥nico del elevador ac luma nos est√° destruyendo cobrando por hacerlo somos muchos los afectados desquite va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23cf0973031f6388a6bacb5306160f57e5f23cbdbb597cdb6726ca6e459aa3e5</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>Azuay</td>\n",
       "      <td>257</td>\n",
       "      <td>No quiero arrecharme, pero estos HDP de Corpoelec quitan la luz hoy q hay agua y se puede lavar!!! üò§\\n\\nCdo hay electricidad, no hay agua \\nCdo hay agua, no hay electricidad.\\nP√≥nganse d acuerdo n...</td>\n",
       "      <td>no quiero arrecharme pero estos hdp corpoelec quitan la luz hoy hay agua se puede lavar cdo hay electricidad no hay agua cdo hay agua no hay electricidad p√≥nganse acuerdo nojodas ten√≠a desahogarme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           Tweet_ID  \\\n",
       "0  c3c923bab9a5006041fee2df8da9a2173b2de335f62342eebe05f0208c97e6c1   \n",
       "1  23cf0973031f6388a6bacb5306160f57e5f23cbdbb597cdb6726ca6e459aa3e5   \n",
       "\n",
       "   Created_At Location_Mentioned  tweet_length  \\\n",
       "0  2024-07-22              Quito           167   \n",
       "1  2024-12-01              Azuay           257   \n",
       "\n",
       "                                                                                                                                                                                                      Text  \\\n",
       "0                                  Se fue la luz y se da√±√≥ el panel electr√≥nico del elevador y el AC. Luma nos est√° destruyendo y cobrando por hacerlo. Somos muchos los afectados. El desquite va. üëäüèªüëäüèªüëäüèª   \n",
       "1  No quiero arrecharme, pero estos HDP de Corpoelec quitan la luz hoy q hay agua y se puede lavar!!! üò§\\n\\nCdo hay electricidad, no hay agua \\nCdo hay agua, no hay electricidad.\\nP√≥nganse d acuerdo n...   \n",
       "\n",
       "                                                                                                                                                                                                Text_Final  \n",
       "0                                                            se fue la luz se da√±√≥ panel electr√≥nico del elevador ac luma nos est√° destruyendo cobrando por hacerlo somos muchos los afectados desquite va  \n",
       "1  no quiero arrecharme pero estos hdp corpoelec quitan la luz hoy hay agua se puede lavar cdo hay electricidad no hay agua cdo hay agua no hay electricidad p√≥nganse acuerdo nojodas ten√≠a desahogarme...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;32mDataset exportado exitosamente como:\u001b[0m tweets_procesados_final.csv\n",
      "Total de registros exportados: 3676\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar solo las columnas requeridas\n",
    "columnas_finales = ['Tweet_ID', 'Created_At', 'Location_Mentioned', 'tweet_length', 'Text', 'Text_Final']\n",
    "df_exportar = df_final_espanol[columnas_finales].copy()\n",
    "\n",
    "# Verificar las columnas seleccionadas\n",
    "print(\"\\033[1mColumnas en el dataset final:\\033[0m\")\n",
    "print(df_exportar.columns.tolist())\n",
    "\n",
    "# Verificar ejemplo de datos\n",
    "print(\"\\n\\033[1mMuestra del dataset final:\\033[0m\")\n",
    "display(df_exportar.head(2))\n",
    "\n",
    "# Guardar a CSV (versi√≥n compatible con todos los caracteres)\n",
    "nombre_archivo = 'tweets_procesados_final.csv'\n",
    "df_exportar.to_csv(nombre_archivo, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\n\\033[1;32mDataset exportado exitosamente como:\\033[0m {nombre_archivo}\")\n",
    "print(f\"Total de registros exportados: {len(df_exportar)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52417744-89d0-437e-b057-4c7abdc45fab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
