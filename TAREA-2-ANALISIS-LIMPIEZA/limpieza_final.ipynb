{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "44c21d86-2e61-408c-9f3f-3b47d28fadb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import hashlib\n",
    "from langdetect import detect, DetectorFactory\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "\n",
    "# Configuración para detección de idioma consistente\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# Configuración de pandas para mostrar más columnas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "665b85f9-3f2c-4ac6-bc0a-a68217dd8393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInformación inicial del dataset:\u001b[0m\n",
      "Registros totales: 4052\n",
      "Columnas originales: ['Tweet_ID', 'Username', 'Text', 'Created_At', 'Location_Mentioned', 'tweet_length']\n",
      "\n",
      "Primeras filas del dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Username</th>\n",
       "      <th>Text</th>\n",
       "      <th>Created_At</th>\n",
       "      <th>Location_Mentioned</th>\n",
       "      <th>tweet_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1828598353636086250</td>\n",
       "      <td>SAJO</td>\n",
       "      <td>Se fue la luz y se dañó el panel electrónico del elevador y el AC. Luma nos está destruyendo y cobrando por hacerlo. Somos muchos los afectados. El desquite va. 👊🏻👊🏻👊🏻</td>\n",
       "      <td>2024-07-22</td>\n",
       "      <td>Quito</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1788212151393423687</td>\n",
       "      <td>🌸♡🌸Elizαβετh🌸♡🌸</td>\n",
       "      <td>No quiero arrecharme, pero estos HDP de Corpoelec quitan la luz hoy q hay agua y se puede lavar!!! 😤\\n\\nCdo hay electricidad, no hay agua \\nCdo hay agua, no hay electricidad.\\nPónganse d acuerdo n...</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>Azuay</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1801749927090847994</td>\n",
       "      <td>Jay Fonseca</td>\n",
       "      <td>🌌 A dos días del apagón masivo que dejó a medio archipiélago a oscuras, ciudadanos reclamaron esta tarde la salida de LUMA Energy y de Genera PR, los dos operadores privados del sistema eléctrico....</td>\n",
       "      <td>2024-10-15</td>\n",
       "      <td>Guayaquil</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tweet_ID         Username  \\\n",
       "0  1828598353636086250             SAJO   \n",
       "1  1788212151393423687  🌸♡🌸Elizαβετh🌸♡🌸   \n",
       "2  1801749927090847994      Jay Fonseca   \n",
       "\n",
       "                                                                                                                                                                                                      Text  \\\n",
       "0                                  Se fue la luz y se dañó el panel electrónico del elevador y el AC. Luma nos está destruyendo y cobrando por hacerlo. Somos muchos los afectados. El desquite va. 👊🏻👊🏻👊🏻   \n",
       "1  No quiero arrecharme, pero estos HDP de Corpoelec quitan la luz hoy q hay agua y se puede lavar!!! 😤\\n\\nCdo hay electricidad, no hay agua \\nCdo hay agua, no hay electricidad.\\nPónganse d acuerdo n...   \n",
       "2  🌌 A dos días del apagón masivo que dejó a medio archipiélago a oscuras, ciudadanos reclamaron esta tarde la salida de LUMA Energy y de Genera PR, los dos operadores privados del sistema eléctrico....   \n",
       "\n",
       "   Created_At Location_Mentioned  tweet_length  \n",
       "0  2024-07-22              Quito           167  \n",
       "1  2024-12-01              Azuay           257  \n",
       "2  2024-10-15          Guayaquil           299  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargar el dataset\n",
    "df = pd.read_csv('limpiar_enalces.csv')\n",
    "\n",
    "# Mostrar información inicial del dataset\n",
    "print(\"\\033[1mInformación inicial del dataset:\\033[0m\")\n",
    "print(f\"Registros totales: {len(df)}\")\n",
    "print(f\"Columnas originales: {df.columns.tolist()}\")\n",
    "print(\"\\nPrimeras filas del dataset:\")\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d862b7ff-1007-4910-a4c4-85d999f14083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mHasheando Tweet_ID...\u001b[0m\n",
      "\u001b[1mEliminando columna Username...\u001b[0m\n",
      "\n",
      "\u001b[1mDataset después de hashear y eliminar:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Created_At</th>\n",
       "      <th>Location_Mentioned</th>\n",
       "      <th>tweet_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c3c923bab9a5006041fee2df8da9a2173b2de335f62342eebe05f0208c97e6c1</td>\n",
       "      <td>Se fue la luz y se dañó el panel electrónico del elevador y el AC. Luma nos está destruyendo y cobrando por hacerlo. Somos muchos los afectados. El desquite va. 👊🏻👊🏻👊🏻</td>\n",
       "      <td>2024-07-22</td>\n",
       "      <td>Quito</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23cf0973031f6388a6bacb5306160f57e5f23cbdbb597cdb6726ca6e459aa3e5</td>\n",
       "      <td>No quiero arrecharme, pero estos HDP de Corpoelec quitan la luz hoy q hay agua y se puede lavar!!! 😤\\n\\nCdo hay electricidad, no hay agua \\nCdo hay agua, no hay electricidad.\\nPónganse d acuerdo n...</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>Azuay</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33da3cb8621b2ce82a4eb6441dfabf4a059ddde7348fadebdb78a4b11370728a</td>\n",
       "      <td>🌌 A dos días del apagón masivo que dejó a medio archipiélago a oscuras, ciudadanos reclamaron esta tarde la salida de LUMA Energy y de Genera PR, los dos operadores privados del sistema eléctrico....</td>\n",
       "      <td>2024-10-15</td>\n",
       "      <td>Guayaquil</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           Tweet_ID  \\\n",
       "0  c3c923bab9a5006041fee2df8da9a2173b2de335f62342eebe05f0208c97e6c1   \n",
       "1  23cf0973031f6388a6bacb5306160f57e5f23cbdbb597cdb6726ca6e459aa3e5   \n",
       "2  33da3cb8621b2ce82a4eb6441dfabf4a059ddde7348fadebdb78a4b11370728a   \n",
       "\n",
       "                                                                                                                                                                                                      Text  \\\n",
       "0                                  Se fue la luz y se dañó el panel electrónico del elevador y el AC. Luma nos está destruyendo y cobrando por hacerlo. Somos muchos los afectados. El desquite va. 👊🏻👊🏻👊🏻   \n",
       "1  No quiero arrecharme, pero estos HDP de Corpoelec quitan la luz hoy q hay agua y se puede lavar!!! 😤\\n\\nCdo hay electricidad, no hay agua \\nCdo hay agua, no hay electricidad.\\nPónganse d acuerdo n...   \n",
       "2  🌌 A dos días del apagón masivo que dejó a medio archipiélago a oscuras, ciudadanos reclamaron esta tarde la salida de LUMA Energy y de Genera PR, los dos operadores privados del sistema eléctrico....   \n",
       "\n",
       "   Created_At Location_Mentioned  tweet_length  \n",
       "0  2024-07-22              Quito           167  \n",
       "1  2024-12-01              Azuay           257  \n",
       "2  2024-10-15          Guayaquil           299  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Función para hashear el Tweet_ID\n",
    "def hashear_id(tweet_id):\n",
    "    if pd.isna(tweet_id):\n",
    "        return None\n",
    "    return hashlib.sha256(str(tweet_id).encode()).hexdigest()\n",
    "\n",
    "# Aplicar hashing al Tweet_ID\n",
    "print(\"\\033[1mHasheando Tweet_ID...\\033[0m\")\n",
    "df['Tweet_ID'] = df['Tweet_ID'].apply(hashear_id)\n",
    "\n",
    "# Eliminar la columna Username\n",
    "print(\"\\033[1mEliminando columna Username...\\033[0m\")\n",
    "df.drop(columns=['Username'], inplace=True)\n",
    "\n",
    "# Verificar cambios\n",
    "print(\"\\n\\033[1mDataset después de hashear y eliminar:\\033[0m\")\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e01b8bc3-cb3b-4ab2-a530-c58a4417ff36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mProcesando limpieza de texto...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4052/4052 [00:00<00:00, 19478.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRegistros después de limpieza:\u001b[0m 4052\n",
      "\u001b[1mRegistros eliminados:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "def limpiar_texto_mejorado(texto):\n",
    "    if pd.isna(texto) or texto == '':\n",
    "        return \"\"\n",
    "    \n",
    "    # Convertir a string por si acaso\n",
    "    texto = str(texto)\n",
    "    \n",
    "    # 1. Eliminar saltos de línea y unir todo en una línea\n",
    "    texto = re.sub(r'\\n|\\r|\\t', ' ', texto)\n",
    "    \n",
    "    # 2. Eliminar enlaces (http, https, t.co, etc.)\n",
    "    texto = re.sub(r'http\\S+|www\\S+|https?://\\S+|t\\.co/\\S+', '', texto, flags=re.IGNORECASE)\n",
    "    \n",
    "    # 3. Eliminar menciones (@usuario)\n",
    "    texto = re.sub(r'@\\w+', '', texto)\n",
    "    \n",
    "    # 4. Eliminar completamente el hashtag y todo lo que le sigue\n",
    "    texto = re.sub(r'#\\S+', '', texto)  # \n",
    "    \n",
    "    # 5. Eliminar emojis y símbolos especiales (patrón ampliado)\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticonos\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # símbolos & pictogramas\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transporte & símbolos\n",
    "        u\"\\U0001F700-\\U0001F77F\"  # alquimia\n",
    "        u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "        u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "        u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "        u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "        u\"\\U000024C2-\\U0001F251\" \n",
    "        u\"\\U0001F004-\\U0001F0CF\"\n",
    "        u\"\\U0001F170-\\U0001F251\"\n",
    "        \"•→←↑↓«»⏰\"  # Símbolos adicionales específicos\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    texto = emoji_pattern.sub(r'', texto)\n",
    "    \n",
    "    # 6. Eliminar caracteres especiales pero conservar signos de puntuación básicos\n",
    "    caracteres_especiales = r'[|*{}\\[\\]()/&%\"¬=°$\\'¿¡~+]'\n",
    "    texto = re.sub(caracteres_especiales, ' ', texto)\n",
    "    \n",
    "    # 7. Eliminar números\n",
    "    texto = re.sub(r'\\d+', '', texto)\n",
    "    \n",
    "    # 8. Convertir a minúsculas\n",
    "    texto = texto.lower()\n",
    "    \n",
    "    # 9. Eliminar puntos suspensivos, comillas y patrones especiales\n",
    "    texto = re.sub(r'\\.{2,}', ' ', texto)  # Puntos suspensivos\n",
    "    texto = re.sub(r'…', ' ', texto)  # Puntos suspensivos unicode\n",
    "    texto = re.sub(r'´|`', '', texto)  # Acentos sueltos\n",
    "    \n",
    "    # 10. Eliminar comillas de todo tipo (incluyendo las angulares)\n",
    "    comillas = r'[\\'\\\"\\‘\\’\\“\\”\\´\\`«»]'\n",
    "    texto = re.sub(comillas, '', texto)\n",
    "    \n",
    "    # 11. Normalizar espacios múltiples y bordes\n",
    "    texto = re.sub(r'\\s{2,}', ' ', texto)  # Espacios múltiples\n",
    "    texto = texto.strip()\n",
    "    \n",
    "    # 13. Eliminar palabras sueltas muy cortas (1-2 letras) que no aportan significado\n",
    "    palabras_relevantes = ['no', 'si', 'se', 'me', 'te', 'le', 'lo', 'la', 'los', 'las', \n",
    "                          'un', 'una', 'uno', 'unos', 'unas', 'al', 'del', 'él', 'ella']\n",
    "    texto = ' '.join([word for word in texto.split() \n",
    "                     if len(word) > 2 or word in palabras_relevantes])\n",
    "    \n",
    "    return texto\n",
    "\n",
    "# Función para detectar texto válido (no vacío después de limpieza)\n",
    "def es_texto_valido(texto):\n",
    "    texto_limpio = limpiar_texto_mejorado(texto)\n",
    "    return len(texto_limpio.strip()) > 3  # Consideramos válido si tiene más de 3 caracteres\n",
    "\n",
    "# Aplicar limpieza mejorada con barra de progreso\n",
    "print(\"\\033[1mProcesando limpieza de texto...\\033[0m\")\n",
    "tqdm.pandas()\n",
    "df['Text_Clean'] = df['Text'].progress_apply(limpiar_texto_mejorado)\n",
    "\n",
    "# Filtrar solo textos válidos\n",
    "df_filtrado = df[df['Text'].apply(es_texto_valido)].copy()\n",
    "print(f\"\\033[1mRegistros después de limpieza:\\033[0m {len(df_filtrado)}\")\n",
    "print(f\"\\033[1mRegistros eliminados:\\033[0m {len(df) - len(df_filtrado)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a97a5d81-33d3-4f37-bb3f-ca7a18d2abf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFiltrando por idioma español...\u001b[0m\n",
      "\u001b[1mRegistros finales:\u001b[0m 3815\n",
      "\u001b[1mRegistros eliminados por idioma:\u001b[0m 237\n"
     ]
    }
   ],
   "source": [
    "# Función mejorada para detección de idioma con manejo de errores\n",
    "def es_espanol_mejorado(texto):\n",
    "    try:\n",
    "        # Si el texto es muy corto, no podemos detectar idioma confiablemente\n",
    "        if len(texto) < 10:\n",
    "            return True  # Asumimos que es español para no perder datos\n",
    "        \n",
    "        # Detectar idioma\n",
    "        return detect(texto) == 'es'\n",
    "    except:\n",
    "        return True  # En caso de error, lo mantenemos para no perder datos\n",
    "\n",
    "# Filtrar por idioma español (con enfoque conservador para no perder datos)\n",
    "print(\"\\033[1mFiltrando por idioma español...\\033[0m\")\n",
    "df_final = df_filtrado[df_filtrado['Text_Clean'].apply(es_espanol_mejorado)].copy()\n",
    "print(f\"\\033[1mRegistros finales:\\033[0m {len(df_final)}\")\n",
    "print(f\"\\033[1mRegistros eliminados por idioma:\\033[0m {len(df_filtrado) - len(df_final)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0afe38f1-da9c-4369-9643-1336b8e9b852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3815/3815 [00:00<00:00, 47132.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mVerificación Final de Ruido Residual:\u001b[0m\n",
      "URLs residuales: 0 tweets (0.00%)\n",
      "HTML tags: 0 tweets (0.00%)\n",
      "Puntuación múltiple: 0 tweets (0.00%)\n",
      "Caracteres especiales no permitidos: 7 tweets (0.19%)\n",
      "Números residuales: 0 tweets (0.00%)\n",
      "Letras repetidas: 0 tweets (0.00%)\n",
      "\n",
      "\u001b[1;32m¡Proceso completado exitosamente!\u001b[0m\n",
      "Total tweets procesados: 3676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuración para evitar warnings\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "# Función de limpieza mejorada\n",
    "def limpiar_texto_final(texto):\n",
    "    if pd.isna(texto) or texto == '':\n",
    "        return \"\"\n",
    "    \n",
    "    texto = str(texto)\n",
    "    \n",
    "    # 1. Corregir letras repetidas (sin grupos problemáticos)\n",
    "    texto = re.sub(r'([a-zA-ZáéíóúüñÁÉÍÓÚÜÑ])\\1{2,}', lambda m: m.group(1), texto)\n",
    "    \n",
    "    # 2. Eliminar caracteres especiales excepto tildes y ñ\n",
    "    texto = re.sub(r'[^\\w\\sáéíóúüñÁÉÍÓÚÜÑ]', '', texto)\n",
    "    \n",
    "    # 3. Normalizar espacios\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "    \n",
    "    return texto\n",
    "\n",
    "# Crear copia explícita para evitar SettingWithCopyWarning\n",
    "df_final_clean = df_final.copy()\n",
    "\n",
    "# Aplicar limpieza\n",
    "tqdm.pandas()\n",
    "df_final_clean.loc[:, 'Text_Final'] = df_final_clean['Text_Clean'].progress_apply(limpiar_texto_final)\n",
    "\n",
    "# Lista de palabras en portugués a filtrar\n",
    "palabras_portugues = [\n",
    "    'obrigado', 'obrigada', 'por favor', 'você', 'sim', 'não', \n",
    "    'com licença', 'bom dia', 'boa tarde', 'boa noite', 'louça'\n",
    "]\n",
    "\n",
    "# Filtrar registros en portugués (sin regex para evitar warnings)\n",
    "df_final_espanol = df_final_clean[\n",
    "    ~df_final_clean['Text_Final'].str.lower().str.contains('|'.join(palabras_portugues), na=False)\n",
    "]\n",
    "\n",
    "# Patrones de verificación (sin grupos de captura)\n",
    "noise_patterns_final = {\n",
    "    'URLs residuales': r'https?:|www\\.',\n",
    "    'HTML tags': r'&lt;|&gt;|<[a-z]+>',\n",
    "    'Puntuación múltiple': r'![!]+|\\?[\\?]+|\\.{2,}',\n",
    "    'Caracteres especiales no permitidos': r'[^a-z0-9\\sáéíóúüñ]',\n",
    "    'Números residuales': r'\\b\\d\\d+\\b',\n",
    "    'Letras repetidas': r'([a-záéíóúüñ])\\1\\1'\n",
    "}\n",
    "\n",
    "print(\"\\n\\033[1mVerificación Final de Ruido Residual:\\033[0m\")\n",
    "\n",
    "# Función segura para contar patrones (sin warnings)\n",
    "def contar_patrones_seguro(serie, pattern):\n",
    "    try:\n",
    "        # Convertir a minúsculas y usar str.count() en lugar de contains()\n",
    "        return serie.str.lower().str.count(pattern).sum()\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "noise_counts = {}\n",
    "for name, pattern in noise_patterns_final.items():\n",
    "    count = contar_patrones_seguro(df_final_espanol['Text_Final'], pattern)\n",
    "    noise_counts[name] = count\n",
    "    print(f\"{name}: {count} tweets ({count/len(df_final_espanol)*100:.2f}%)\")\n",
    "\n",
    "# Mostrar solo resultados sin ejemplos específicos\n",
    "print(\"\\n\\033[1;32m¡Proceso completado exitosamente!\\033[0m\")\n",
    "print(f\"Total tweets procesados: {len(df_final_espanol)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "625f1826-35bb-4553-913d-358df4b423ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mColumnas en el dataset final:\u001b[0m\n",
      "['Tweet_ID', 'Created_At', 'Location_Mentioned', 'tweet_length', 'Text', 'Text_Final']\n",
      "\n",
      "\u001b[1mMuestra del dataset final:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Created_At</th>\n",
       "      <th>Location_Mentioned</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c3c923bab9a5006041fee2df8da9a2173b2de335f62342eebe05f0208c97e6c1</td>\n",
       "      <td>2024-07-22</td>\n",
       "      <td>Quito</td>\n",
       "      <td>167</td>\n",
       "      <td>Se fue la luz y se dañó el panel electrónico del elevador y el AC. Luma nos está destruyendo y cobrando por hacerlo. Somos muchos los afectados. El desquite va. 👊🏻👊🏻👊🏻</td>\n",
       "      <td>se fue la luz se dañó panel electrónico del elevador ac luma nos está destruyendo cobrando por hacerlo somos muchos los afectados desquite va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23cf0973031f6388a6bacb5306160f57e5f23cbdbb597cdb6726ca6e459aa3e5</td>\n",
       "      <td>2024-12-01</td>\n",
       "      <td>Azuay</td>\n",
       "      <td>257</td>\n",
       "      <td>No quiero arrecharme, pero estos HDP de Corpoelec quitan la luz hoy q hay agua y se puede lavar!!! 😤\\n\\nCdo hay electricidad, no hay agua \\nCdo hay agua, no hay electricidad.\\nPónganse d acuerdo n...</td>\n",
       "      <td>no quiero arrecharme pero estos hdp corpoelec quitan la luz hoy hay agua se puede lavar cdo hay electricidad no hay agua cdo hay agua no hay electricidad pónganse acuerdo nojodas tenía desahogarme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           Tweet_ID  \\\n",
       "0  c3c923bab9a5006041fee2df8da9a2173b2de335f62342eebe05f0208c97e6c1   \n",
       "1  23cf0973031f6388a6bacb5306160f57e5f23cbdbb597cdb6726ca6e459aa3e5   \n",
       "\n",
       "   Created_At Location_Mentioned  tweet_length  \\\n",
       "0  2024-07-22              Quito           167   \n",
       "1  2024-12-01              Azuay           257   \n",
       "\n",
       "                                                                                                                                                                                                      Text  \\\n",
       "0                                  Se fue la luz y se dañó el panel electrónico del elevador y el AC. Luma nos está destruyendo y cobrando por hacerlo. Somos muchos los afectados. El desquite va. 👊🏻👊🏻👊🏻   \n",
       "1  No quiero arrecharme, pero estos HDP de Corpoelec quitan la luz hoy q hay agua y se puede lavar!!! 😤\\n\\nCdo hay electricidad, no hay agua \\nCdo hay agua, no hay electricidad.\\nPónganse d acuerdo n...   \n",
       "\n",
       "                                                                                                                                                                                                Text_Final  \n",
       "0                                                            se fue la luz se dañó panel electrónico del elevador ac luma nos está destruyendo cobrando por hacerlo somos muchos los afectados desquite va  \n",
       "1  no quiero arrecharme pero estos hdp corpoelec quitan la luz hoy hay agua se puede lavar cdo hay electricidad no hay agua cdo hay agua no hay electricidad pónganse acuerdo nojodas tenía desahogarme...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;32mDataset exportado exitosamente como:\u001b[0m tweets_procesados_final.csv\n",
      "Total de registros exportados: 3676\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar solo las columnas requeridas\n",
    "columnas_finales = ['Tweet_ID', 'Created_At', 'Location_Mentioned', 'tweet_length', 'Text', 'Text_Final']\n",
    "df_exportar = df_final_espanol[columnas_finales].copy()\n",
    "\n",
    "# Verificar las columnas seleccionadas\n",
    "print(\"\\033[1mColumnas en el dataset final:\\033[0m\")\n",
    "print(df_exportar.columns.tolist())\n",
    "\n",
    "# Verificar ejemplo de datos\n",
    "print(\"\\n\\033[1mMuestra del dataset final:\\033[0m\")\n",
    "display(df_exportar.head(2))\n",
    "\n",
    "# Guardar a CSV (versión compatible con todos los caracteres)\n",
    "nombre_archivo = 'tweets_procesados_final.csv'\n",
    "df_exportar.to_csv(nombre_archivo, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\n\\033[1;32mDataset exportado exitosamente como:\\033[0m {nombre_archivo}\")\n",
    "print(f\"Total de registros exportados: {len(df_exportar)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52417744-89d0-437e-b057-4c7abdc45fab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
